"""
SNR 10dB + k=4 + ê±°ë¦¬ 0.5m ê¸°ì¤€ ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ íƒì§€ ì‹œìŠ¤í…œ
k-NN ì—°ê²° ìˆ˜ëŠ” ì¤„ì´ê³  ê±°ë¦¬ëŠ” ê¸°ì¡´ ìœ ì§€
"""
import torch
import torch.optim as optim
from torch_geometric.loader import DataLoader
from torch.utils.data import random_split
import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
import os

from data_structures import RadarPoint, RadarFrame
from hybrid_ghost_gnn import HybridGhostGNN, create_graph_data

class OptimizedGhostDetectorDataset:
    """k=4, ê±°ë¦¬=0.5m ìµœì í™”ëœ ë°ì´í„°ì…‹"""
    
    def __init__(self, 
                 radar_data_path: str,
                 lidar_data_path: str,
                 distance_threshold: float = 0.5,  # ê¸°ì¡´ ê±°ë¦¬ ìœ ì§€
                 snr_threshold: float = 10.0,
                 k: int = 4,  # ì—°ê²° ìˆ˜ë§Œ ê°ì†Œ
                 min_points_per_frame: int = 5):
        
        self.radar_data_path = radar_data_path
        self.lidar_data_path = lidar_data_path
        self.distance_threshold = distance_threshold
        self.snr_threshold = snr_threshold
        self.k = k
        self.min_points_per_frame = min_points_per_frame
        
        self.radar_frames = []
        self.lidar_frames = []
        self.processed_data = []
        
        self._load_data()
        self._process_data()
    
    def _load_data(self):
        """ë°ì´í„° ë¡œë”©"""
        print("ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ë ˆì´ë” ë°ì´í„° ë¡œë”©
        self.radar_frames = []
        current_frame = []
        current_time = None
        
        with open(self.radar_data_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    time = float(parts[0])
                    x, y = float(parts[1]), float(parts[2])
                    velocity = float(parts[3])
                    snr = float(parts[4])
                    
                    if current_time is None:
                        current_time = time
                    
                    if abs(time - current_time) < 1e-6:
                        current_frame.append(RadarPoint(x, y, velocity, snr))
                    else:
                        if len(current_frame) >= self.min_points_per_frame:
                            self.radar_frames.append(current_frame)
                        current_frame = [RadarPoint(x, y, velocity, snr)]
                        current_time = time
        
        if len(current_frame) >= self.min_points_per_frame:
            self.radar_frames.append(current_frame)
        
        print(f"ë ˆì´ë” í”„ë ˆì„: {len(self.radar_frames)}ê°œ")
        
        # LiDAR ë°ì´í„° ë¡œë”©
        self.lidar_frames = []
        current_frame = []
        current_time = None
        
        with open(self.lidar_data_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 4:
                    time = float(parts[0])
                    x, y = float(parts[1]), float(parts[2])
                    
                    if current_time is None:
                        current_time = time
                    
                    if abs(time - current_time) < 1e-6:
                        current_frame.append((x, y))
                    else:
                        self.lidar_frames.append(current_frame)
                        current_frame = [(x, y)]
                        current_time = time
        
        if current_frame:
            self.lidar_frames.append(current_frame)
        
        print(f"LiDAR í”„ë ˆì„: {len(self.lidar_frames)}ê°œ")
    
    def _process_data(self):
        """ë°ì´í„° ì²˜ë¦¬ ë° ë¼ë²¨ë§"""
        print("ìµœì í™”ëœ ê¸°ì¤€ìœ¼ë¡œ SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§ ì¤‘...")
        
        total_frames = len(self.radar_frames)
        total_nodes = 0
        total_real = 0
        total_ghost = 0
        
        for i, radar_frame in enumerate(self.radar_frames):
            if i % 500 == 0:
                print(f"ì²˜ë¦¬ ì¤‘: {i}/{total_frames}")
            
            if len(radar_frame) < self.min_points_per_frame:
                continue
            
            # í•´ë‹¹í•˜ëŠ” LiDAR í”„ë ˆì„ ì°¾ê¸°
            lidar_frame = self.lidar_frames[i] if i < len(self.lidar_frames) else []
            
            # ìµœì í™”ëœ ê¸°ì¤€ìœ¼ë¡œ ë¼ë²¨ë§
            labels = self._label_points_optimized(radar_frame, lidar_frame)
            
            # ê·¸ë˜í”„ ë°ì´í„° ìƒì„± (k=4 ì‚¬ìš©)
            graph_data = create_graph_data(radar_frame, labels, k=self.k)
            
            if graph_data.x.size(0) > 0:
                self.processed_data.append(graph_data)
                total_nodes += len(labels)
                total_real += sum(labels)
                total_ghost += len(labels) - sum(labels)
        
        print(f"\n=== ìµœì í™”ëœ ê¸°ì¤€ ë°ì´í„°ì…‹ í†µê³„ ===")
        print(f"ğŸ“ ê±°ë¦¬ ì„ê³„ê°’: {self.distance_threshold}m (ê¸°ì¡´ ìœ ì§€)")
        print(f"ğŸ“¡ SNR ì„ê³„ê°’: {self.snr_threshold}dB")
        print(f"ğŸ”— k-NN ì—°ê²°: {self.k}ê°œ (ê¸°ì¡´ 8ê°œ â†’ 4ê°œ)")
        print(f"ì´ ê·¸ë˜í”„: {len(self.processed_data)}ê°œ")
        print(f"ì´ ë…¸ë“œ: {total_nodes}ê°œ")
        print(f"ì‹¤ì œ íƒ€ê²Ÿ: {total_real} ({total_real/total_nodes*100:.1f}%)")
        print(f"ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ: {total_ghost} ({total_ghost/total_nodes*100:.1f}%)")
    
    def _label_points_optimized(self, radar_points, lidar_frame):
        """ìµœì í™”ëœ SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§"""
        if not lidar_frame:
            return [0] * len(radar_points)
        
        radar_positions = np.array([[p.x, p.y] for p in radar_points])
        lidar_positions = np.array(lidar_frame)
        snr_values = np.array([p.rcs for p in radar_points])
        
        # ê±°ë¦¬ ê³„ì‚°
        distances = cdist(radar_positions, lidar_positions)
        min_distances = np.min(distances, axis=1)
        
        # ìµœì í™”ëœ SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§
        labels = []
        for distance, snr in zip(min_distances, snr_values):
            if distance <= self.distance_threshold and snr >= self.snr_threshold:
                labels.append(1)  # ì‹¤ì œ íƒ€ê²Ÿ
            else:
                labels.append(0)  # ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ
        
        return labels
    
    def __len__(self):
        return len(self.processed_data)
    
    def __getitem__(self, idx):
        return self.processed_data[idx]

def create_training_visualization(dataset, save_path="optimized_training_analysis.png"):
    """ìµœì í™”ëœ í•™ìŠµ ë°ì´í„° ì‹œê°í™”"""
    print("ìµœì í™”ëœ í•™ìŠµ ë°ì´í„° ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # ë°ì´í„° ìˆ˜ì§‘
    all_radar_x, all_radar_y = [], []
    all_lidar_x, all_lidar_y = [], []
    all_real_x, all_real_y = [], []
    all_ghost_x, all_ghost_y = [], []
    all_snr_values = []
    all_distances = []
    
    # ì›ë³¸ ë°ì´í„°ì—ì„œ ìˆ˜ì§‘
    for i, radar_frame in enumerate(dataset.radar_frames[:100]):  # ì²˜ìŒ 100í”„ë ˆì„ë§Œ
        lidar_frame = dataset.lidar_frames[i] if i < len(dataset.lidar_frames) else []
        
        # LiDAR í¬ì¸íŠ¸
        if lidar_frame:
            lidar_x = [p[0] for p in lidar_frame]
            lidar_y = [p[1] for p in lidar_frame]
            all_lidar_x.extend(lidar_x)
            all_lidar_y.extend(lidar_y)
        
        # ë ˆì´ë” í¬ì¸íŠ¸ì™€ ë¼ë²¨
        labels = dataset._label_points_optimized(radar_frame, lidar_frame)
        
        # ê±°ë¦¬ ê³„ì‚°
        if lidar_frame:
            radar_positions = np.array([[p.x, p.y] for p in radar_frame])
            lidar_positions = np.array(lidar_frame)
            distances = cdist(radar_positions, lidar_positions)
            min_distances = np.min(distances, axis=1)
        else:
            min_distances = [float('inf')] * len(radar_frame)
        
        for j, (point, label, dist) in enumerate(zip(radar_frame, labels, min_distances)):
            all_radar_x.append(point.x)
            all_radar_y.append(point.y)
            all_snr_values.append(point.rcs)
            all_distances.append(dist)
            
            if label == 1:
                all_real_x.append(point.x)
                all_real_y.append(point.y)
            else:
                all_ghost_x.append(point.x)
                all_ghost_y.append(point.y)
    
    # ì‹œê°í™”
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))
    
    # 1. ì›ë³¸ ë°ì´í„°
    if all_lidar_x:
        ax1.scatter(all_lidar_x, all_lidar_y, c='blue', s=1, alpha=0.3, label=f'LiDAR ({len(all_lidar_x)})')
    scatter1 = ax1.scatter(all_radar_x, all_radar_y, c=all_snr_values, s=20, 
                          cmap='viridis', alpha=0.8, label=f'Radar ({len(all_radar_x)})')
    ax1.set_title('1. Training Data: LiDAR + Radar (SNR colored)', fontsize=14)
    ax1.set_xlabel('X (m)')
    ax1.set_ylabel('Y (m)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    plt.colorbar(scatter1, ax=ax1, label='SNR (dB)')
    
    # 2. ìµœì í™”ëœ ê¸°ì¤€ ë¼ë²¨ë§ ê²°ê³¼
    if all_real_x:
        ax2.scatter(all_real_x, all_real_y, c='green', s=20, alpha=0.8, 
                   label=f'Real Targets ({len(all_real_x)})')
    if all_ghost_x:
        ax2.scatter(all_ghost_x, all_ghost_y, c='red', s=20, alpha=0.8, 
                   label=f'Ghost Targets ({len(all_ghost_x)})')
    if all_lidar_x:
        ax2.scatter(all_lidar_x, all_lidar_y, c='blue', s=1, alpha=0.2, label='LiDAR')
    ax2.set_title('2. Optimized Labeling (k=4, 0.5m + 10dB)', fontsize=14)
    ax2.set_xlabel('X (m)')
    ax2.set_ylabel('Y (m)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ê±°ë¦¬ ë¶„í¬
    valid_distances = [d for d in all_distances if d != float('inf')]
    ax3.hist(valid_distances, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')
    ax3.axvline(x=0.5, color='green', linestyle='--', linewidth=2, label='0.5m threshold')
    ax3.axvline(x=0.3, color='red', linestyle='--', linewidth=2, label='0.3m (previous)')
    ax3.set_title('3. Distance Distribution (Radar to nearest LiDAR)', fontsize=14)
    ax3.set_xlabel('Distance (m)')
    ax3.set_ylabel('Count')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. í†µê³„ ì •ë³´
    ax4.axis('off')
    real_ratio = len(all_real_x) / len(all_radar_x) * 100 if all_radar_x else 0
    ghost_ratio = len(all_ghost_x) / len(all_radar_x) * 100 if all_radar_x else 0
    avg_snr = np.mean(all_snr_values) if all_snr_values else 0
    avg_dist = np.mean(valid_distances) if valid_distances else 0
    
    stats_text = f"""
    ğŸ“Š Optimized Training Data Analysis
    
    ğŸ¯ Optimized Criteria:
    â€¢ Distance threshold: 0.5m (restored)
    â€¢ k-NN connections: 4 (reduced from 8)
    â€¢ SNR threshold: 10.0 dB
    
    ğŸ“ˆ Labeling Results:
    â€¢ Total radar points: {len(all_radar_x):,}
    â€¢ Real targets: {len(all_real_x):,} ({real_ratio:.1f}%)
    â€¢ Ghost targets: {len(all_ghost_x):,} ({ghost_ratio:.1f}%)
    
    ğŸ“Š Data Statistics:
    â€¢ Average SNR: {avg_snr:.1f} dB
    â€¢ Average distance: {avg_dist:.3f} m
    â€¢ LiDAR points: {len(all_lidar_x):,}
    
    ğŸ¯ Expected Benefits:
    â€¢ Balanced precision/recall
    â€¢ Reduced neighbor influence
    â€¢ Better generalization
    """
    ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=12,
            verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Optimized training visualization saved: {save_path}")
    
    return len(all_real_x), len(all_ghost_x)

def train_optimized_ghost_detector():
    """ìµœì í™”ëœ ê³ ìŠ¤íŠ¸ íƒì§€ê¸° í•™ìŠµ"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ ìµœì í™”ëœ GPU í•™ìŠµ ì‹œì‘! ì¥ì¹˜: {device}")
    print(f"ğŸ“ ê±°ë¦¬ ì„ê³„ê°’: 0.5m (ê¸°ì¡´ ìœ ì§€)")
    print(f"ğŸ”— k-NN ì—°ê²°: 4ê°œ (ê¸°ì¡´ 8ê°œì—ì„œ ê°ì†Œ)")
    
    # ìµœì í™”ëœ ë°ì´í„°ì…‹
    dataset = OptimizedGhostDetectorDataset(
        radar_data_path="RadarMap_v2.txt",
        lidar_data_path="LiDARMap_v2.txt",
        distance_threshold=0.5,  # ê¸°ì¡´ ê±°ë¦¬ ìœ ì§€
        snr_threshold=10.0,
        k=4  # ì—°ê²° ìˆ˜ë§Œ ê°ì†Œ
    )
    
    # í•™ìŠµ ë°ì´í„° ì‹œê°í™”
    real_count, ghost_count = create_training_visualization(dataset)
    
    # ë°ì´í„° ë¶„í• 
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    # ë°ì´í„° ë¡œë”
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = HybridGhostGNN(input_dim=6, hidden_dim=128, num_layers=3).to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.005)
    criterion = torch.nn.BCELoss()
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
    
    # í•™ìŠµ
    print("ğŸ¯ ìµœì í™”ëœ ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµ ì‹œì‘...")
    best_val_acc = 0
    
    for epoch in range(50):
        # í›ˆë ¨
        model.train()
        total_loss = 0
        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            out = model(batch)
            loss = criterion(torch.sigmoid(out.squeeze()), batch.y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        # ê²€ì¦
        if (epoch + 1) % 10 == 0:
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for batch in val_loader:
                    batch = batch.to(device)
                    out = model(batch)
                    pred = (torch.sigmoid(out.squeeze()) > 0.5).float()
                    correct += (pred == batch.y).sum().item()
                    total += batch.y.size(0)
            
            val_acc = correct / total * 100
            scheduler.step(total_loss)
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save(model.state_dict(), 'ghost_detector_k4_0.5m.pth')
            
            print(f"Epoch {epoch+1}/50 | Train Loss: {total_loss/len(train_loader):.4f} | Val Acc: {val_acc:.2f}% | Best: {best_val_acc:.2f}%")
    
    print(f"ğŸ‰ ìµœì í™”ëœ í•™ìŠµ ì™„ë£Œ! ìµœê³  ì •í™•ë„: {best_val_acc:.2f}%")
    return best_val_acc

if __name__ == "__main__":
    train_optimized_ghost_detector()
