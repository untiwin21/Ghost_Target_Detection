"""
SNR + ê±°ë¦¬ ì¡°í•© ë ˆì´ë” ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ íƒì§€ ì‹œìŠ¤í…œ
"""
import torch
import torch.optim as optim
from torch_geometric.loader import DataLoader
from torch.utils.data import random_split
import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
import os

from data_structures import RadarPoint, RadarFrame
from hybrid_ghost_gnn import HybridGhostGNN, create_graph_data

class GhostDetectorDataset:
    """SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§ ì „ìš© ë°ì´í„°ì…‹"""
    
    def __init__(self, 
                 radar_data_path: str,
                 lidar_data_path: str,
                 distance_threshold: float = 0.5,
                 snr_threshold: float = 20.0,
                 k: int = 8,
                 min_points_per_frame: int = 5):
        
        self.radar_data_path = radar_data_path
        self.lidar_data_path = lidar_data_path
        self.distance_threshold = distance_threshold
        self.snr_threshold = snr_threshold
        self.k = k
        self.min_points_per_frame = min_points_per_frame
        
        self.radar_frames = []
        self.lidar_frames = []
        self.processed_data = []
        
        self._load_data()
        self._process_data()
    
    def _load_data(self):
        """ë°ì´í„° ë¡œë”©"""
        print("ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ë ˆì´ë” ë°ì´í„° ë¡œë”©: time x y velocity SNR
        self.radar_frames = []
        current_frame = []
        current_time = None
        
        with open(self.radar_data_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    time = float(parts[0])
                    x = float(parts[1])
                    y = float(parts[2])
                    velocity = float(parts[3])  # ì‚¬ìš© ì•ˆí•¨
                    snr = float(parts[4])
                    
                    if current_time is None:
                        current_time = time
                    
                    if abs(time - current_time) > 0.01:
                        if current_frame:
                            self.radar_frames.append(current_frame)
                        current_frame = []
                        current_time = time
                    
                    current_frame.append(RadarPoint(x, y, 0.0, snr))  # vr=0, rcs=snr
            
            if current_frame:
                self.radar_frames.append(current_frame)
        
        # LiDAR ë°ì´í„° ë¡œë”©: time x y intensity
        self.lidar_frames = []
        current_frame = []
        current_time = None
        
        with open(self.lidar_data_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 4:
                    time = float(parts[0])
                    x = float(parts[1])
                    y = float(parts[2])
                    
                    if current_time is None:
                        current_time = time
                    
                    if abs(time - current_time) > 0.01:
                        if current_frame:
                            self.lidar_frames.append(current_frame)
                        current_frame = []
                        current_time = time
                    
                    current_frame.append((x, y))
            
            if current_frame:
                self.lidar_frames.append(current_frame)
        
        print(f"ë ˆì´ë” í”„ë ˆì„: {len(self.radar_frames)}ê°œ")
        print(f"LiDAR í”„ë ˆì„: {len(self.lidar_frames)}ê°œ")
    
    def _process_data(self):
        """SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§ìœ¼ë¡œ ë°ì´í„° ì²˜ë¦¬"""
        print("SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§ ì¤‘...")
        
        min_frames = min(len(self.radar_frames), len(self.lidar_frames))
        
        for frame_idx in range(min_frames):
            if frame_idx % 500 == 0:
                print(f"ì²˜ë¦¬ ì¤‘: {frame_idx}/{min_frames}")
            
            radar_frame = self.radar_frames[frame_idx]
            lidar_frame = self.lidar_frames[frame_idx]
            
            if len(radar_frame) < self.min_points_per_frame:
                continue
            
            labels = self._label_points_combined(radar_frame, lidar_frame)
            graph_data = create_graph_data(radar_frame, labels, k=self.k)
            
            if graph_data.x.size(0) > 0:
                self.processed_data.append(graph_data)
        
        # í†µê³„ ì¶œë ¥
        total_nodes = sum(data.x.size(0) for data in self.processed_data)
        total_real = sum(data.y.sum().item() for data in self.processed_data)
        total_ghost = total_nodes - total_real
        
        print(f"\n=== ë°ì´í„°ì…‹ í†µê³„ (SNR + ê±°ë¦¬ ì¡°í•©) ===")
        print(f"ì´ ê·¸ë˜í”„: {len(self.processed_data)}ê°œ")
        print(f"ì´ ë…¸ë“œ: {total_nodes}ê°œ")
        print(f"ì‹¤ì œ íƒ€ê²Ÿ: {total_real} ({total_real/total_nodes*100:.1f}%)")
        print(f"ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ: {total_ghost} ({total_ghost/total_nodes*100:.1f}%)")
    
    def _label_points_combined(self, radar_points, lidar_frame):
        """SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§"""
        if not lidar_frame:
            return [0] * len(radar_points)
        
        radar_positions = np.array([[p.x, p.y] for p in radar_points])
        lidar_positions = np.array(lidar_frame)
        snr_values = np.array([p.rcs for p in radar_points])
        
        # ê±°ë¦¬ ê³„ì‚°
        distances = cdist(radar_positions, lidar_positions)
        min_distances = np.min(distances, axis=1)
        
        # SNR + ê±°ë¦¬ ì¡°í•© ë¼ë²¨ë§
        labels = []
        for distance, snr in zip(min_distances, snr_values):
            if distance <= self.distance_threshold and snr >= self.snr_threshold:
                labels.append(1)  # ì‹¤ì œ íƒ€ê²Ÿ
            else:
                labels.append(0)  # ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ
        
        return labels
    
    def __len__(self):
        return len(self.processed_data)
    
    def __getitem__(self, idx):
        return self.processed_data[idx]

def train_ghost_detector():
    """ê³ ìŠ¤íŠ¸ íƒì§€ê¸° í•™ìŠµ"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ GPU í•™ìŠµ ì‹œì‘! ì¥ì¹˜: {device}")
    
    # ë°ì´í„°ì…‹
    dataset = GhostDetectorDataset(
        radar_data_path="RadarMap_v2.txt",
        lidar_data_path="LiDARMap_v2.txt",
        distance_threshold=0.5,
        snr_threshold=20.0
    )
    
    # ë°ì´í„° ë¶„í• 
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # ëª¨ë¸
    model = HybridGhostGNN(input_dim=6, hidden_dim=128, dropout=0.1)
    model.to(device)
    
    optimizer = optim.Adam(model.parameters(), lr=0.005)
    criterion = torch.nn.BCELoss()
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10)
    
    print("ğŸ¯ í•™ìŠµ ì‹œì‘...")
    best_val_acc = 0
    
    for epoch in range(50):
        # í•™ìŠµ
        model.train()
        total_train_loss = 0
        train_batches = 0
        
        for data in train_loader:
            data = data.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output.squeeze(), data.y)
            loss.backward()
            optimizer.step()
            total_train_loss += loss.item()
            train_batches += 1
        
        # ê²€ì¦
        if (epoch + 1) % 10 == 0:
            model.eval()
            correct_preds, total_nodes = 0, 0
            
            with torch.no_grad():
                for data in val_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = (output.squeeze() > 0.5).int()
                    correct_preds += (preds == data.y.int()).sum().item()
                    total_nodes += data.num_nodes
            
            val_acc = (correct_preds / total_nodes) * 100
            scheduler.step(val_acc)
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save(model.state_dict(), 'ghost_detector.pth')
            
            avg_train_loss = total_train_loss / train_batches
            print(f"Epoch {epoch+1:02d}/50 | Train Loss: {avg_train_loss:.4f} | Val Acc: {val_acc:.2f}% | Best: {best_val_acc:.2f}%")
    
    print(f"ğŸ‰ í•™ìŠµ ì™„ë£Œ! ìµœê³  ì •í™•ë„: {best_val_acc:.2f}%")
    return dataset, model

if __name__ == '__main__':
    print("ğŸ¯ SNR + ê±°ë¦¬ ì¡°í•© ê³ ìŠ¤íŠ¸ íƒì§€ ì‹œìŠ¤í…œ")
    dataset, model = train_ghost_detector()
