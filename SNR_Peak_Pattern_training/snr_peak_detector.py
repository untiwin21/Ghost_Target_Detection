"""
SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ìœ ë¦¬ë²½ ê°ì§€ ì‹œìŠ¤í…œ
SNRì´ ë´‰ìš°ë¦¬ í˜•íƒœë¡œ ë‚˜íƒ€ë‚˜ë©´ ìœ ë¦¬ë²½ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ê³ ìŠ¤íŠ¸ ì²˜ë¦¬
"""
import torch
import torch.optim as optim
from torch_geometric.loader import DataLoader
from torch.utils.data import random_split
import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
from scipy.signal import find_peaks
from sklearn.cluster import DBSCAN
import os

from data_structures import RadarPoint, RadarFrame
from hybrid_ghost_gnn import HybridGhostGNN, create_graph_data

class SNRPeakPatternDataset:
    """SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ìœ ë¦¬ë²½ ê°ì§€ ë°ì´í„°ì…‹"""
    
    def __init__(self, 
                 radar_data_path: str,
                 lidar_data_path: str,
                 distance_threshold: float = 0.4,
                 snr_threshold: float = 15.0,
                 k: int = 5,
                 peak_detection_distance: float = 2.0,  # ë´‰ìš°ë¦¬ ê°ì§€ ë²”ìœ„
                 min_points_per_frame: int = 5):
        
        self.radar_data_path = radar_data_path
        self.lidar_data_path = lidar_data_path
        self.distance_threshold = distance_threshold
        self.snr_threshold = snr_threshold
        self.k = k
        self.peak_detection_distance = peak_detection_distance
        self.min_points_per_frame = min_points_per_frame
        
        self.radar_frames = []
        self.lidar_frames = []
        self.processed_data = []
        
        self._load_data()
        self._process_data()
    
    def _load_data(self):
        """ë°ì´í„° ë¡œë”©"""
        print("ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ë ˆì´ë” ë°ì´í„° ë¡œë”©
        self.radar_frames = []
        current_frame = []
        current_time = None
        
        with open(self.radar_data_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    time = float(parts[0])
                    x, y = float(parts[1]), float(parts[2])
                    velocity = float(parts[3])
                    snr = float(parts[4])
                    
                    if current_time is None:
                        current_time = time
                    
                    if abs(time - current_time) < 1e-6:
                        current_frame.append(RadarPoint(x, y, velocity, snr))
                    else:
                        if len(current_frame) >= self.min_points_per_frame:
                            self.radar_frames.append(current_frame)
                        current_frame = [RadarPoint(x, y, velocity, snr)]
                        current_time = time
        
        if len(current_frame) >= self.min_points_per_frame:
            self.radar_frames.append(current_frame)
        
        print(f"ë ˆì´ë” í”„ë ˆì„: {len(self.radar_frames)}ê°œ")
        
        # LiDAR ë°ì´í„° ë¡œë”©
        self.lidar_frames = []
        current_frame = []
        current_time = None
        
        with open(self.lidar_data_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 4:
                    time = float(parts[0])
                    x, y = float(parts[1]), float(parts[2])
                    
                    if current_time is None:
                        current_time = time
                    
                    if abs(time - current_time) < 1e-6:
                        current_frame.append((x, y))
                    else:
                        self.lidar_frames.append(current_frame)
                        current_frame = [(x, y)]
                        current_time = time
        
        if current_frame:
            self.lidar_frames.append(current_frame)
        
        print(f"LiDAR í”„ë ˆì„: {len(self.lidar_frames)}ê°œ")
    
    def _detect_snr_peaks(self, radar_points):
        """SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê°ì§€"""
        if len(radar_points) < 5:
            return []
        
        # ë ˆì´ë” í¬ì¸íŠ¸ë¥¼ ê±°ë¦¬ ìˆœìœ¼ë¡œ ì •ë ¬
        points_with_range = [(np.sqrt(p.x**2 + p.y**2), p.rcs, i, p) for i, p in enumerate(radar_points)]
        points_with_range.sort(key=lambda x: x[0])  # ê±°ë¦¬ìˆœ ì •ë ¬
        
        ranges = [p[0] for p in points_with_range]
        snrs = [p[1] for p in points_with_range]
        indices = [p[2] for p in points_with_range]
        
        # SNR ë´‰ìš°ë¦¬ ê°ì§€
        glass_wall_indices = []
        
        # ì´ë™ í‰ê· ìœ¼ë¡œ ìŠ¤ë¬´ë”©
        if len(snrs) >= 5:
            window_size = min(5, len(snrs))
            smoothed_snrs = np.convolve(snrs, np.ones(window_size)/window_size, mode='same')
            
            # ë´‰ìš°ë¦¬ ê°ì§€ (prominence ê¸°ë°˜)
            peaks, properties = find_peaks(smoothed_snrs, 
                                         prominence=5,  # ìµœì†Œ 5dB ëŒì¶œ
                                         distance=3)    # ìµœì†Œ 3í¬ì¸íŠ¸ ê°„ê²©
            
            # ê°ì§€ëœ ë´‰ìš°ë¦¬ ì£¼ë³€ í¬ì¸íŠ¸ë“¤ì„ ìœ ë¦¬ë²½ í›„ë³´ë¡œ ë¶„ë¥˜
            for peak_idx in peaks:
                # ë´‰ìš°ë¦¬ ì£¼ë³€ í¬ì¸íŠ¸ë“¤ í™•ì¸
                start_idx = max(0, peak_idx - 2)
                end_idx = min(len(indices), peak_idx + 3)
                
                for i in range(start_idx, end_idx):
                    original_idx = indices[i]
                    glass_wall_indices.append(original_idx)
        
        return glass_wall_indices
    
    def _detect_spatial_snr_peaks(self, radar_points):
        """ê³µê°„ì  SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê°ì§€ (2D)"""
        glass_wall_indices = []
        
        if len(radar_points) < 10:
            return glass_wall_indices
        
        # ê³µê°„ì  í´ëŸ¬ìŠ¤í„°ë§
        positions = np.array([[p.x, p.y] for p in radar_points])
        snrs = np.array([p.rcs for p in radar_points])
        
        # DBSCANìœ¼ë¡œ ê³µê°„ì  í´ëŸ¬ìŠ¤í„° í˜•ì„±
        clustering = DBSCAN(eps=1.0, min_samples=3).fit(positions)
        labels = clustering.labels_
        
        # ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ SNR íŒ¨í„´ ë¶„ì„
        unique_labels = set(labels)
        for label in unique_labels:
            if label == -1:  # ë…¸ì´ì¦ˆ ì œì™¸
                continue
            
            cluster_indices = np.where(labels == label)[0]
            if len(cluster_indices) < 3:
                continue
            
            cluster_snrs = snrs[cluster_indices]
            
            # í´ëŸ¬ìŠ¤í„° ë‚´ SNR ë¶„ì‚°ì´ ë†’ìœ¼ë©´ (ë´‰ìš°ë¦¬ íŒ¨í„´) ìœ ë¦¬ë²½ í›„ë³´
            snr_std = np.std(cluster_snrs)
            snr_max = np.max(cluster_snrs)
            snr_min = np.min(cluster_snrs)
            
            # ë´‰ìš°ë¦¬ íŒ¨í„´ ì¡°ê±´:
            # 1. ë†’ì€ SNR ë¶„ì‚° (ë‹¤ì–‘í•œ ë°˜ì‚¬ ê°•ë„)
            # 2. ìµœëŒ€-ìµœì†Œ SNR ì°¨ì´ê°€ í¼
            # 3. í‰ê·  SNRì´ ë†’ìŒ (ê°•í•œ ë°˜ì‚¬)
            if (snr_std > 8 and 
                (snr_max - snr_min) > 15 and 
                np.mean(cluster_snrs) > 20):
                
                glass_wall_indices.extend(cluster_indices.tolist())
        
        return glass_wall_indices
    
    def _process_data(self):
        """SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ë° ë¼ë²¨ë§"""
        print("SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ë¼ë²¨ë§ ì¤‘...")
        
        total_frames = len(self.radar_frames)
        total_nodes = 0
        total_real = 0
        total_ghost = 0
        glass_wall_detected = 0
        glass_wall_points = 0
        
        for i, radar_frame in enumerate(self.radar_frames):
            if i % 500 == 0:
                print(f"ì²˜ë¦¬ ì¤‘: {i}/{total_frames}")
            
            if len(radar_frame) < self.min_points_per_frame:
                continue
            
            # í•´ë‹¹í•˜ëŠ” LiDAR í”„ë ˆì„ ì°¾ê¸°
            lidar_frame = self.lidar_frames[i] if i < len(self.lidar_frames) else []
            
            # SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ë¼ë²¨ë§
            labels = self._label_points_peak_aware(radar_frame, lidar_frame)
            
            # ìœ ë¦¬ë²½ ê°ì§€ í†µê³„
            glass_indices = self._detect_spatial_snr_peaks(radar_frame)
            if glass_indices:
                glass_wall_detected += 1
                glass_wall_points += len(glass_indices)
            
            # ê·¸ë˜í”„ ë°ì´í„° ìƒì„±
            graph_data = create_graph_data(radar_frame, labels, k=self.k)
            
            if graph_data.x.size(0) > 0:
                self.processed_data.append(graph_data)
                total_nodes += len(labels)
                total_real += sum(labels)
                total_ghost += len(labels) - sum(labels)
        
        print(f"\n=== SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ë°ì´í„°ì…‹ í†µê³„ ===")
        print(f"ğŸ“ ê±°ë¦¬ ì„ê³„ê°’: {self.distance_threshold}m")
        print(f"ğŸ“¡ SNR ì„ê³„ê°’: {self.snr_threshold}dB")
        print(f"ğŸ”— k-NN ì—°ê²°: {self.k}ê°œ")
        print(f"ğŸ”ï¸ ë´‰ìš°ë¦¬ ê°ì§€ ë²”ìœ„: {self.peak_detection_distance}m")
        print(f"ì´ ê·¸ë˜í”„: {len(self.processed_data)}ê°œ")
        print(f"ì´ ë…¸ë“œ: {total_nodes}ê°œ")
        print(f"ì‹¤ì œ íƒ€ê²Ÿ: {total_real} ({total_real/total_nodes*100:.1f}%)")
        print(f"ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ: {total_ghost} ({total_ghost/total_nodes*100:.1f}%)")
        print(f"\nğŸªŸ ìœ ë¦¬ë²½ ê°ì§€ í†µê³„:")
        print(f"ìœ ë¦¬ë²½ íŒ¨í„´ ê°ì§€ í”„ë ˆì„: {glass_wall_detected}ê°œ")
        print(f"ìœ ë¦¬ë²½ í›„ë³´ í¬ì¸íŠ¸: {glass_wall_points}ê°œ")
    
    def _label_points_peak_aware(self, radar_points, lidar_frame):
        """SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ì¸ì‹ ê¸°ë°˜ ë¼ë²¨ë§"""
        if not lidar_frame:
            return [0] * len(radar_points)
        
        radar_positions = np.array([[p.x, p.y] for p in radar_points])
        lidar_positions = np.array(lidar_frame)
        snr_values = np.array([p.rcs for p in radar_points])
        
        # ê±°ë¦¬ ê³„ì‚°
        distances = cdist(radar_positions, lidar_positions)
        min_distances = np.min(distances, axis=1)
        
        # ìœ ë¦¬ë²½ í›„ë³´ í¬ì¸íŠ¸ ê°ì§€
        glass_wall_indices = self._detect_spatial_snr_peaks(radar_points)
        
        # ë¼ë²¨ë§
        labels = []
        for i, (distance, snr) in enumerate(zip(min_distances, snr_values)):
            # ê¸°ë³¸ ì¡°ê±´ í™•ì¸
            basic_condition = distance <= self.distance_threshold and snr >= self.snr_threshold
            
            # ìœ ë¦¬ë²½ íŒ¨í„´ í™•ì¸
            is_glass_wall = i in glass_wall_indices
            
            if basic_condition and not is_glass_wall:
                labels.append(1)  # ì‹¤ì œ íƒ€ê²Ÿ
            else:
                labels.append(0)  # ê³ ìŠ¤íŠ¸ íƒ€ê²Ÿ (ìœ ë¦¬ë²½ í¬í•¨)
        
        return labels
    
    def __len__(self):
        return len(self.processed_data)
    
    def __getitem__(self, idx):
        return self.processed_data[idx]

def create_peak_pattern_visualization(dataset, save_path="snr_peak_pattern_analysis.png"):
    """SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ë¶„ì„ ì‹œê°í™”"""
    print("SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ë¶„ì„ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # ë°ì´í„° ìˆ˜ì§‘
    all_radar_x, all_radar_y = [], []
    all_lidar_x, all_lidar_y = [], []
    all_real_x, all_real_y = [], []
    all_ghost_x, all_ghost_y = [], []
    glass_wall_x, glass_wall_y = [], []
    all_snr_values = []
    
    # ì›ë³¸ ë°ì´í„°ì—ì„œ ìˆ˜ì§‘
    for i, radar_frame in enumerate(dataset.radar_frames[:50]):  # ì²˜ìŒ 50í”„ë ˆì„ë§Œ
        lidar_frame = dataset.lidar_frames[i] if i < len(dataset.lidar_frames) else []
        
        # LiDAR í¬ì¸íŠ¸
        if lidar_frame:
            lidar_x = [p[0] for p in lidar_frame]
            lidar_y = [p[1] for p in lidar_frame]
            all_lidar_x.extend(lidar_x)
            all_lidar_y.extend(lidar_y)
        
        # ìœ ë¦¬ë²½ í›„ë³´ ê°ì§€
        glass_indices = dataset._detect_spatial_snr_peaks(radar_frame)
        
        # ë ˆì´ë” í¬ì¸íŠ¸ì™€ ë¼ë²¨
        labels = dataset._label_points_peak_aware(radar_frame, lidar_frame)
        
        for j, (point, label) in enumerate(zip(radar_frame, labels)):
            all_radar_x.append(point.x)
            all_radar_y.append(point.y)
            all_snr_values.append(point.rcs)
            
            if j in glass_indices:
                glass_wall_x.append(point.x)
                glass_wall_y.append(point.y)
            
            if label == 1:
                all_real_x.append(point.x)
                all_real_y.append(point.y)
            else:
                all_ghost_x.append(point.x)
                all_ghost_y.append(point.y)
    
    # ì‹œê°í™”
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))
    
    # 1. SNR ë¶„í¬ + ìœ ë¦¬ë²½ ê°ì§€
    if all_lidar_x:
        ax1.scatter(all_lidar_x, all_lidar_y, c='blue', s=1, alpha=0.3, label=f'LiDAR ({len(all_lidar_x)})')
    
    scatter1 = ax1.scatter(all_radar_x, all_radar_y, c=all_snr_values, s=15, 
                          cmap='viridis', alpha=0.7, label=f'Radar ({len(all_radar_x)})')
    
    if glass_wall_x:
        ax1.scatter(glass_wall_x, glass_wall_y, c='red', s=50, alpha=0.8, 
                   marker='x', label=f'Glass Wall Pattern ({len(glass_wall_x)})')
    
    ax1.set_title('1. SNR Distribution + Glass Wall Detection', fontsize=14)
    ax1.set_xlabel('X (m)')
    ax1.set_ylabel('Y (m)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    plt.colorbar(scatter1, ax=ax1, label='SNR (dB)')
    
    # 2. ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ë¼ë²¨ë§ ê²°ê³¼
    if all_real_x:
        ax2.scatter(all_real_x, all_real_y, c='green', s=15, alpha=0.8, 
                   label=f'Real Targets ({len(all_real_x)})')
    if all_ghost_x:
        ax2.scatter(all_ghost_x, all_ghost_y, c='red', s=15, alpha=0.8, 
                   label=f'Ghost Targets ({len(all_ghost_x)})')
    if glass_wall_x:
        ax2.scatter(glass_wall_x, glass_wall_y, c='orange', s=30, alpha=1.0, 
                   marker='s', label=f'Glass Wall Ghost ({len(glass_wall_x)})')
    
    if all_lidar_x:
        ax2.scatter(all_lidar_x, all_lidar_y, c='blue', s=1, alpha=0.2, label='LiDAR')
    ax2.set_title('2. Peak Pattern-Aware Labeling', fontsize=14)
    ax2.set_xlabel('X (m)')
    ax2.set_ylabel('Y (m)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ì˜ˆì‹œ
    # ëŒ€í‘œì ì¸ í”„ë ˆì„ì—ì„œ ê±°ë¦¬ë³„ SNR íŒ¨í„´ ë³´ê¸°
    example_frame = dataset.radar_frames[10] if len(dataset.radar_frames) > 10 else dataset.radar_frames[0]
    points_with_range = [(np.sqrt(p.x**2 + p.y**2), p.rcs) for p in example_frame]
    points_with_range.sort(key=lambda x: x[0])
    
    ranges = [p[0] for p in points_with_range]
    snrs = [p[1] for p in points_with_range]
    
    ax3.plot(ranges, snrs, 'b-o', alpha=0.7, label='SNR vs Range')
    ax3.set_xlabel('Range (m)')
    ax3.set_ylabel('SNR (dB)')
    ax3.set_title('3. SNR Pattern Example (Range vs SNR)', fontsize=14)
    ax3.grid(True, alpha=0.3)
    ax3.legend()
    
    # ë´‰ìš°ë¦¬ ê°ì§€ í‘œì‹œ
    if len(snrs) >= 5:
        from scipy.signal import find_peaks
        smoothed_snrs = np.convolve(snrs, np.ones(3)/3, mode='same')
        peaks, _ = find_peaks(smoothed_snrs, prominence=3, distance=2)
        if len(peaks) > 0:
            ax3.plot([ranges[i] for i in peaks], [smoothed_snrs[i] for i in peaks], 
                    'ro', markersize=8, label='Detected Peaks')
            ax3.legend()
    
    # 4. í†µê³„ ì •ë³´
    ax4.axis('off')
    glass_ratio = len(glass_wall_x) / len(all_radar_x) * 100 if all_radar_x else 0
    
    stats_text = f"""
    ğŸ”ï¸ SNR Peak Pattern Analysis
    
    ğŸ¯ Detection Strategy:
    â€¢ SNR peak detection in spatial clusters
    â€¢ High SNR variance indicates glass walls
    â€¢ Peak prominence threshold: 5dB
    â€¢ Cluster analysis with DBSCAN
    
    ğŸ“Š Pattern Detection Results:
    â€¢ Total radar points: {len(all_radar_x):,}
    â€¢ Glass wall patterns: {len(glass_wall_x):,} ({glass_ratio:.1f}%)
    â€¢ Real targets: {len(all_real_x):,} ({len(all_real_x)/len(all_radar_x)*100:.1f}%)
    â€¢ Ghost targets: {len(all_ghost_x):,} ({len(all_ghost_x)/len(all_radar_x)*100:.1f}%)
    
    ğŸªŸ Glass Wall Characteristics:
    â€¢ SNR variance > 8dB in clusters
    â€¢ Max-Min SNR difference > 15dB
    â€¢ Average SNR > 20dB
    â€¢ Multiple reflection peaks
    
    ğŸ’¡ Benefits:
    â€¢ Automatic glass wall detection
    â€¢ Reduces false positives from reflections
    â€¢ Physics-based pattern recognition
    â€¢ No manual wall mapping needed
    """
    
    ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=11,
            verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightsteelblue", alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"SNR peak pattern visualization saved: {save_path}")

def train_snr_peak_detector():
    """SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ê³ ìŠ¤íŠ¸ íƒì§€ê¸° í•™ìŠµ"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ GPU í•™ìŠµ ì‹œì‘! ì¥ì¹˜: {device}")
    print(f"ğŸ”ï¸ ìœ ë¦¬ë²½ SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ìë™ ê°ì§€ ë° ê³ ìŠ¤íŠ¸ ì²˜ë¦¬")
    
    # SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ ë°ì´í„°ì…‹
    dataset = SNRPeakPatternDataset(
        radar_data_path="RadarMap_v2.txt",
        lidar_data_path="LiDARMap_v2.txt",
        distance_threshold=0.4,
        snr_threshold=15.0,
        k=5,
        peak_detection_distance=2.0
    )
    
    # í•™ìŠµ ë°ì´í„° ì‹œê°í™”
    create_peak_pattern_visualization(dataset)
    
    # ë°ì´í„° ë¶„í• 
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    # ë°ì´í„° ë¡œë”
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = HybridGhostGNN(input_dim=6, hidden_dim=128, num_layers=3).to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.005)
    criterion = torch.nn.BCELoss()
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
    
    # í•™ìŠµ
    print("ğŸ¯ SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ í•™ìŠµ ì‹œì‘...")
    best_val_acc = 0
    
    for epoch in range(50):
        # í›ˆë ¨
        model.train()
        total_loss = 0
        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            out = model(batch)
            loss = criterion(torch.sigmoid(out.squeeze()), batch.y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        # ê²€ì¦
        if (epoch + 1) % 10 == 0:
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for batch in val_loader:
                    batch = batch.to(device)
                    out = model(batch)
                    pred = (torch.sigmoid(out.squeeze()) > 0.5).float()
                    correct += (pred == batch.y).sum().item()
                    total += batch.y.size(0)
            
            val_acc = correct / total * 100
            scheduler.step(total_loss)
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save(model.state_dict(), 'snr_peak_detector.pth')
            
            print(f"Epoch {epoch+1}/50 | Train Loss: {total_loss/len(train_loader):.4f} | Val Acc: {val_acc:.2f}% | Best: {best_val_acc:.2f}%")
    
    print(f"ğŸ‰ SNR ë´‰ìš°ë¦¬ íŒ¨í„´ ê¸°ë°˜ í•™ìŠµ ì™„ë£Œ! ìµœê³  ì •í™•ë„: {best_val_acc:.2f}%")
    return best_val_acc

if __name__ == "__main__":
    train_snr_peak_detector()
